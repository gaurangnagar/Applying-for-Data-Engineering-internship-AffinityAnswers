{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f1db3bb",
   "metadata": {},
   "source": [
    "# Applying for Data Engineering internship\n",
    "\n",
    "## AffinityAnswers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de884d0",
   "metadata": {},
   "source": [
    "#### QUES: Imagine there is a file full of Twitter tweets by various users and you are provided a set of words that indicates racial slurs. Write a program that can indicate the degree of profanity for each sentence in the file. Write in any programming language (preferably in Python) - make any assumptions, but remember to state them. Please place the code in GitHub with proper documentation and share. Please respond in 2-3 days."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d8c5c4",
   "metadata": {},
   "source": [
    "ASSUMPTIONS:\n",
    "\n",
    "The twitter tweets are in a csv file named like \"tweets.csv\".\n",
    "\n",
    "Set of words that indicates racial slurs are within in a list.\n",
    "\n",
    "Each word in text file is seperated by space\n",
    "\n",
    "All tweets are in only english language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394f9203",
   "metadata": {},
   "source": [
    "# Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a63d5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f309f3ad",
   "metadata": {},
   "source": [
    "# Function for tokenizing a sentence based on spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86ccf3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text): \n",
    "    return re.findall(r'\\w+', text.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0059741",
   "metadata": {},
   "source": [
    "# Opening the text file consisting of Tweets and reading them into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6725a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Tweets.txt') as f:\n",
    "    lines=[line.rstrip() for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ada5a3e",
   "metadata": {},
   "source": [
    "# List of racial slurs supplied to us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a203ecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "racial_slurs = [\"dumbfuck\",\"bitch\",\"moron\",\"shit\",\"stupid\",\"anal\",\"anus\",\"ballsack\",\"blowjob\",\"blow job\",\n",
    "\"boner\",\"clitoris\",\"cock\",\"cunt\",\"dick\",\"dildo\",\"dyke\",\"fag\",\"fuck\",\"jizz\",\"labia\",\"muff\",\"nigger\",\"nigga\",\"penis\", \n",
    "\"piss\",\"pussy\",\"scrotum\",\"sex\",\"shit\",\"slut\",\"smegma\",\"spunk\",\"twat\",\"vagina\",\"wank\",\"whore\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b1c7f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment: 1. My,color,is,blue,shit,pink ===> profanity_degree: 0.14285714285714285\n",
      "Comment: 2. blue,white,penis,black,indigo,pussy,nigga,teal,green,red ===> profanity_degree: 0.2727272727272727\n",
      "Comment: 3. Rich's,fav,animal,as fuck is,lion ===> profanity_degree: 0.1111111111111111\n",
      "Comment: 4. blue,red,pink,indigo,green ===> profanity_degree: 0.0\n",
      "Comment: 5. BLUE,Green,White,are,sex,present,on,Indian,Flag ===> profanity_degree: 0.1\n"
     ]
    }
   ],
   "source": [
    "for i in lines:\n",
    "    count = 0\n",
    "    profanity_degree = 0\n",
    "    comment_token=tokenize(i)\n",
    "    for word in comment_token:\n",
    "        if word.lower() in racial_slurs:\n",
    "            count = count + 1    \n",
    "\t# degree:number of occurrences normalized by total number\n",
    "    profanity_degree = profanity_degree + count/len(comment_token)\n",
    "    print(\"Comment: \"+ i +\" ===> profanity_degree: \" + str(profanity_degree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43b6be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
